{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "spark_wordcount.ipynb",
      "authorship_tag": "ABX9TyNAIEdWJlhynYdhEZl54eLV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msdevanms/pyspark_training/blob/main/Spark_wordcount.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hn4NE3TP768r"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "GhbKr8NI8N1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create SparkSession and sparkcontext\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "                    .master(\"local\")\\\n",
        "                    .appName('Firstprogram')\\\n",
        "                    .getOrCreate()\n",
        "sc=spark.sparkContext"
      ],
      "metadata": {
        "id": "eQdv0ddS8qu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the input file and Calculating words count\n",
        "text_file = sc.textFile(\"sample_data/README.md\")\n",
        "counts = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
        "                            .map(lambda word: (word, 1)) \\\n",
        "                           .reduceByKey(lambda x, y: x + y)"
      ],
      "metadata": {
        "id": "xOBRUvhP8xBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing each word with its respective count\n",
        "output = counts.collect()\n",
        "for (word, count) in output:\n",
        "    print(\"%s: %i\" % (word, count))"
      ],
      "metadata": {
        "id": "h3LByY5v861g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts_sorted = counts.sortBy(lambda x: x[1])"
      ],
      "metadata": {
        "id": "1hlgjziw_428"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_sorted = counts_sorted.collect()\n",
        "for (word, count) in output_sorted:\n",
        "    print(\"%s: %i\" % (word, count))"
      ],
      "metadata": {
        "id": "m2C8ZppFArYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the input file and Calculating words count\n",
        "text_file = sc.textFile(\"sample_data/README.md\")\n",
        "counts = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
        "                            .filter(lambda word: (word not in [\",\",\"*\", \"'\",\" \",\"\"])) \\\n",
        "                            .map(lambda word: (word, 1)) \\\n",
        "                           .reduceByKey(lambda x, y: x + y)"
      ],
      "metadata": {
        "id": "qblX6PAJCXje"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}